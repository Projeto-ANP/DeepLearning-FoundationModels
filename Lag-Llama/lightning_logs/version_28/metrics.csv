train_loss,step,epoch
9.54587173461914,49,0
8.760926246643066,99,1
8.657268524169922,149,2
8.631572723388672,199,3
8.454507827758789,249,4
8.400067329406738,299,5
8.339359283447266,349,6
8.107168197631836,399,7
7.962430477142334,449,8
7.742924690246582,499,9
7.723083019256592,549,10
7.628442764282227,599,11
7.553918361663818,649,12
7.826568126678467,699,13
7.562377452850342,749,14
7.432839393615723,799,15
7.4126763343811035,849,16
7.353350639343262,899,17
7.249016761779785,949,18
7.326132774353027,999,19
7.192995548248291,1049,20
7.3794426918029785,1099,21
7.091257095336914,1149,22
7.301247596740723,1199,23
7.553008556365967,1249,24
7.022467613220215,1299,25
7.047571182250977,1349,26
7.063246250152588,1399,27
7.108924388885498,1449,28
6.97702693939209,1499,29
7.141425609588623,1549,30
6.838882923126221,1599,31
7.066951751708984,1649,32
6.933761119842529,1699,33
7.044651985168457,1749,34
6.9107794761657715,1799,35
6.70367431640625,1849,36
6.719639301300049,1899,37
7.05453634262085,1949,38
6.960316181182861,1999,39
6.7203569412231445,2049,40
6.6089186668396,2099,41
6.651369094848633,2149,42
6.614455699920654,2199,43
6.7893171310424805,2249,44
6.801529407501221,2299,45
6.624068737030029,2349,46
6.611876964569092,2399,47
6.930978775024414,2449,48
6.706647872924805,2499,49
