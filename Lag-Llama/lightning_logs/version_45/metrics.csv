train_loss,epoch,step
12.535470008850098,0,49
11.757883071899414,1,99
11.608013153076172,2,149
11.588506698608398,3,199
11.393828392028809,4,249
11.319374084472656,5,299
11.219435691833496,6,349
11.16949462890625,7,399
11.013506889343262,8,449
11.006378173828125,9,499
10.844460487365723,10,549
10.827489852905273,11,599
10.6217622756958,12,649
10.542852401733398,13,699
10.597265243530273,14,749
10.427094459533691,15,799
10.364179611206055,16,849
10.28757095336914,17,899
10.3052978515625,18,949
10.336915016174316,19,999
10.129406929016113,20,1049
10.083629608154297,21,1099
10.233687400817871,22,1149
9.957489967346191,23,1199
10.038240432739258,24,1249
9.906961441040039,25,1299
9.8294038772583,26,1349
9.904069900512695,27,1399
9.775605201721191,28,1449
9.716021537780762,29,1499
9.621140480041504,30,1549
9.675230026245117,31,1599
9.675312042236328,32,1649
10.053461074829102,33,1699
9.56441879272461,34,1749
9.514829635620117,35,1799
9.440582275390625,36,1849
9.700732231140137,37,1899
9.83362102508545,38,1949
9.582046508789062,39,1999
9.683743476867676,40,2049
9.595495223999023,41,2099
9.416766166687012,42,2149
9.307320594787598,43,2199
9.292115211486816,44,2249
9.402524948120117,45,2299
9.683167457580566,46,2349
9.566183090209961,47,2399
9.755062103271484,48,2449
9.22098445892334,49,2499
