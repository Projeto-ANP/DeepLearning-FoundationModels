epoch,train_loss,step
0,9.603813171386719,49
1,8.490348815917969,99
2,8.426504135131836,149
3,8.233929634094238,199
4,8.3400297164917,249
5,7.979082107543945,299
6,7.8854475021362305,349
7,7.716413497924805,399
8,7.560739040374756,449
9,7.42848014831543,499
10,7.740751266479492,549
11,7.4325971603393555,599
12,7.462179183959961,649
13,7.306696891784668,699
14,7.1643829345703125,749
15,7.0865797996521,799
16,6.9712724685668945,849
17,7.179128646850586,899
18,7.005424976348877,949
19,7.12618350982666,999
20,6.880037307739258,1049
21,6.9658637046813965,1099
22,6.810108661651611,1149
23,6.879532337188721,1199
24,6.7438249588012695,1249
25,6.771103382110596,1299
26,6.628437042236328,1349
27,7.276708602905273,1399
28,6.709880828857422,1449
29,6.574934482574463,1499
30,6.5576958656311035,1549
31,6.488790512084961,1599
32,6.638540267944336,1649
33,6.5300211906433105,1699
34,6.500615119934082,1749
35,6.508574962615967,1799
36,6.499166488647461,1849
37,6.590153694152832,1899
38,6.44044303894043,1949
39,6.400487899780273,1999
40,6.408680438995361,2049
41,6.344188690185547,2099
42,6.227931976318359,2149
43,6.3232622146606445,2199
44,6.241952896118164,2249
45,6.321353912353516,2299
46,6.563295364379883,2349
47,6.2136664390563965,2399
48,6.253745079040527,2449
49,6.265230178833008,2499
