train_loss,epoch,step
11.159261703491211,0,49
10.142797470092773,1,99
10.023877143859863,2,149
9.960585594177246,3,199
9.876883506774902,4,249
9.82760238647461,5,299
9.578288078308105,6,349
9.533395767211914,7,399
9.417900085449219,8,449
9.564032554626465,9,499
9.183475494384766,10,549
9.15516185760498,11,599
9.029829025268555,12,649
8.891363143920898,13,699
8.794897079467773,14,749
8.992083549499512,15,799
8.692020416259766,16,849
8.672758102416992,17,899
8.525964736938477,18,949
8.707806587219238,19,999
8.515129089355469,20,1049
8.481432914733887,21,1099
8.381326675415039,22,1149
8.287628173828125,23,1199
8.229057312011719,24,1249
8.23631477355957,25,1299
8.218896865844727,26,1349
8.243577003479004,27,1399
8.253256797790527,28,1449
8.275232315063477,29,1499
8.244719505310059,30,1549
8.139826774597168,31,1599
8.074317932128906,32,1649
8.177390098571777,33,1699
7.997380256652832,34,1749
8.028119087219238,35,1799
7.980183124542236,36,1849
7.981235980987549,37,1899
8.173433303833008,38,1949
7.8792829513549805,39,1999
7.924069404602051,40,2049
7.877199649810791,41,2099
7.940176486968994,42,2149
7.793642997741699,43,2199
8.1425199508667,44,2249
7.814993858337402,45,2299
7.850207328796387,46,2349
8.089561462402344,47,2399
7.896005630493164,48,2449
7.756213188171387,49,2499
