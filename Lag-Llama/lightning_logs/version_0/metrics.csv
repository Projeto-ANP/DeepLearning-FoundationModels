epoch,step,train_loss
0,49,8.233073234558105
1,99,6.916094779968262
2,149,6.887564182281494
3,199,6.846790313720703
4,249,6.882037162780762
5,299,6.544456958770752
6,349,6.501400947570801
7,399,6.880650043487549
8,449,6.4877400398254395
9,499,6.7439656257629395
10,549,6.447736740112305
11,599,6.542906284332275
12,649,6.419233322143555
13,699,6.39120626449585
14,749,6.4828081130981445
15,799,6.475162982940674
16,849,6.370469570159912
17,899,6.243411064147949
18,949,6.263275146484375
19,999,6.306146621704102
20,1049,6.381521224975586
21,1099,6.3237152099609375
22,1149,6.2663984298706055
23,1199,6.347780704498291
24,1249,6.367968559265137
25,1299,6.238390922546387
26,1349,6.364889144897461
27,1399,6.2182416915893555
28,1449,6.37826681137085
29,1499,6.1783246994018555
30,1549,6.2785539627075195
31,1599,6.220717906951904
32,1649,6.1049652099609375
33,1699,6.240021228790283
34,1749,6.2110419273376465
35,1799,6.294771671295166
36,1849,6.15995979309082
37,1899,6.178248405456543
38,1949,6.149479866027832
39,1999,6.146641254425049
40,2049,6.130545139312744
41,2099,6.244999885559082
42,2149,6.061708450317383
43,2199,6.111500263214111
44,2249,6.060701370239258
45,2299,6.058382511138916
46,2349,6.100739002227783
47,2399,6.016263008117676
48,2449,6.054957866668701
49,2499,5.998049259185791
