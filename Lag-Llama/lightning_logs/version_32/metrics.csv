train_loss,epoch,step
7.867502212524414,0,49
7.110101222991943,1,99
6.9506964683532715,2,149
6.6056599617004395,3,199
6.379419326782227,4,249
6.091153144836426,5,299
5.871004581451416,6,349
5.732831954956055,7,399
5.6394124031066895,8,449
5.681645393371582,9,499
5.598611831665039,10,549
5.414107799530029,11,599
5.327613353729248,12,649
5.42166805267334,13,699
5.192575454711914,14,749
5.490195274353027,15,799
5.1800312995910645,16,849
5.00187873840332,17,899
5.000586986541748,18,949
4.9463653564453125,19,999
4.991641044616699,20,1049
4.934986114501953,21,1099
4.910775661468506,22,1149
4.9261908531188965,23,1199
4.864352226257324,24,1249
4.847548007965088,25,1299
4.724920272827148,26,1349
4.7523274421691895,27,1399
5.09501838684082,28,1449
4.688991546630859,29,1499
4.737945079803467,30,1549
4.722528457641602,31,1599
4.651171684265137,32,1649
4.521456241607666,33,1699
4.635677337646484,34,1749
4.592339992523193,35,1799
4.899068355560303,36,1849
4.638665676116943,37,1899
4.614177703857422,38,1949
4.48414421081543,39,1999
4.482520580291748,40,2049
4.643373966217041,41,2099
4.6357831954956055,42,2149
4.679024696350098,43,2199
4.560659885406494,44,2249
4.427282810211182,45,2299
4.4481425285339355,46,2349
4.766332149505615,47,2399
4.41572380065918,48,2449
4.340346336364746,49,2499
