train_loss,epoch,step
9.058343887329102,0,49
8.433544158935547,1,99
8.297849655151367,2,149
8.184621810913086,3,199
8.22305965423584,4,249
7.955384731292725,5,299
7.762669563293457,6,349
8.018832206726074,7,399
7.8182692527771,8,449
7.661713123321533,9,499
7.52419900894165,10,549
7.275669097900391,11,599
7.127968788146973,12,649
7.2527899742126465,13,699
7.078305721282959,14,749
7.041469573974609,15,799
7.199713706970215,16,849
6.859464168548584,17,899
7.089972496032715,18,949
7.074610710144043,19,999
7.014655113220215,20,1049
6.961418628692627,21,1099
6.8687591552734375,22,1149
6.698570728302002,23,1199
6.7257399559021,24,1249
6.573671817779541,25,1299
6.6834235191345215,26,1349
6.540002346038818,27,1399
6.436144828796387,28,1449
6.389285087585449,29,1499
6.493037223815918,30,1549
6.445287704467773,31,1599
6.714169979095459,32,1649
6.468504428863525,33,1699
6.383069038391113,34,1749
6.490762710571289,35,1799
6.353031635284424,36,1849
6.5314788818359375,37,1899
6.379461288452148,38,1949
6.344887733459473,39,1999
6.334384918212891,40,2049
6.298274993896484,41,2099
6.6132426261901855,42,2149
6.263371467590332,43,2199
6.448991775512695,44,2249
6.296320915222168,45,2299
6.175860404968262,46,2349
6.379834175109863,47,2399
6.3428497314453125,48,2449
6.244919300079346,49,2499
