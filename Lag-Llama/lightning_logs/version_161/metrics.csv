step,train_loss,epoch
49,7.727146148681641,0
99,7.044881820678711,1
149,6.8435587882995605,2
199,6.463482856750488,3
249,6.219954013824463,4
299,6.214907646179199,5
349,5.832525730133057,6
399,6.02110481262207,7
449,6.22273063659668,8
499,5.531195640563965,9
549,5.5323710441589355,10
599,5.877732753753662,11
649,5.290823459625244,12
699,5.166720390319824,13
749,5.303257942199707,14
799,5.292410850524902,15
849,5.225341796875,16
899,4.987797737121582,17
949,4.9874138832092285,18
999,5.039667129516602,19
1049,5.1314287185668945,20
1099,5.166982650756836,21
1149,4.809028148651123,22
1199,4.841537952423096,23
1249,5.204362869262695,24
1299,4.703446388244629,25
1349,4.640259742736816,26
1399,4.612797737121582,27
1449,4.549936294555664,28
1499,4.794418811798096,29
1549,4.8648834228515625,30
1599,4.533641815185547,31
1649,4.420490741729736,32
1699,4.442287445068359,33
1749,4.384993076324463,34
1799,4.432955741882324,35
1849,4.322196006774902,36
1899,4.444414138793945,37
1949,4.4918036460876465,38
1999,4.397789478302002,39
2049,4.2776594161987305,40
2099,4.201838493347168,41
2149,4.177504062652588,42
2199,4.184414863586426,43
2249,4.195502758026123,44
2299,4.157658576965332,45
2349,4.2663373947143555,46
2399,4.174684524536133,47
2449,4.2736124992370605,48
2499,4.112813472747803,49
