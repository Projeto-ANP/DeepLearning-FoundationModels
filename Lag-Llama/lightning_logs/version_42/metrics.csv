train_loss,epoch,step
11.192739486694336,0,49
10.378573417663574,1,99
10.293734550476074,2,149
10.162619590759277,3,199
10.22152042388916,4,249
9.918512344360352,5,299
9.748712539672852,6,349
9.589015007019043,7,399
9.54161548614502,8,449
9.38196086883545,9,499
9.485597610473633,10,549
9.551039695739746,11,599
9.209386825561523,12,649
9.095514297485352,13,699
8.897357940673828,14,749
8.97339153289795,15,799
8.754173278808594,16,849
8.801865577697754,17,899
8.933046340942383,18,949
8.610003471374512,19,999
8.62963581085205,20,1049
8.595717430114746,21,1099
8.466753959655762,22,1149
8.340274810791016,23,1199
8.459090232849121,24,1249
8.477455139160156,25,1299
8.410935401916504,26,1349
8.252148628234863,27,1399
8.295063018798828,28,1449
8.266289710998535,29,1499
8.35396671295166,30,1549
8.064698219299316,31,1599
8.127885818481445,32,1649
8.085387229919434,33,1699
8.112874984741211,34,1749
7.9729905128479,35,1799
8.18435287475586,36,1849
8.151416778564453,37,1899
8.031892776489258,38,1949
7.962611198425293,39,1999
8.26646900177002,40,2049
8.052515983581543,41,2099
7.915884494781494,42,2149
8.05516529083252,43,2199
7.877805709838867,44,2249
7.864035129547119,45,2299
7.804080963134766,46,2349
8.017128944396973,47,2399
7.854284763336182,48,2449
7.829162120819092,49,2499
