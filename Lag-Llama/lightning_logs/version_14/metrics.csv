train_loss,step,epoch
10.96828842163086,49,0
9.884905815124512,99,1
9.723467826843262,149,2
9.63014030456543,199,3
9.449296951293945,249,4
9.33321475982666,299,5
9.295953750610352,349,6
9.0878324508667,399,7
8.984797477722168,449,8
8.958148002624512,499,9
8.85861873626709,549,10
8.73646068572998,599,11
8.94241714477539,649,12
8.633511543273926,699,13
8.709114074707031,749,14
8.508273124694824,799,15
8.353217124938965,849,16
8.670392036437988,899,17
8.317329406738281,949,18
8.179239273071289,999,19
8.35161018371582,1049,20
8.170879364013672,1099,21
8.447768211364746,1149,22
8.122536659240723,1199,23
8.266241073608398,1249,24
8.061087608337402,1299,25
8.056313514709473,1349,26
7.982269287109375,1399,27
7.949126720428467,1449,28
8.016790390014648,1499,29
7.907544136047363,1549,30
7.830743312835693,1599,31
7.877503871917725,1649,32
7.983130931854248,1699,33
7.863832473754883,1749,34
7.768889904022217,1799,35
7.956891059875488,1849,36
7.778860092163086,1899,37
7.693222522735596,1949,38
7.955989837646484,1999,39
7.83218240737915,2049,40
7.676530361175537,2099,41
7.594213962554932,2149,42
7.6385416984558105,2199,43
7.840392589569092,2249,44
7.633874416351318,2299,45
7.81143045425415,2349,46
7.609128475189209,2399,47
7.539267063140869,2449,48
7.562090873718262,2499,49
