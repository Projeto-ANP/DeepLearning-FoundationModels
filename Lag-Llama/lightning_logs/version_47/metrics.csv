train_loss,epoch,step
5.8397932052612305,0,49
5.036592483520508,1,99
4.655919075012207,2,149
4.242920875549316,3,199
4.0256667137146,4,249
3.8913180828094482,5,299
3.7318878173828125,6,349
3.718447685241699,7,399
3.6145501136779785,8,449
3.3634939193725586,9,499
3.440648078918457,10,549
3.3449954986572266,11,599
3.2367916107177734,12,649
3.1464149951934814,13,699
3.070298671722412,14,749
3.2753827571868896,15,799
3.157205581665039,16,849
3.0509557723999023,17,899
2.9683728218078613,18,949
2.9601526260375977,19,999
2.878251552581787,20,1049
2.9150729179382324,21,1099
2.9323930740356445,22,1149
2.8459272384643555,23,1199
2.9457318782806396,24,1249
2.8643054962158203,25,1299
2.737138032913208,26,1349
2.8796398639678955,27,1399
2.6598148345947266,28,1449
2.852536916732788,29,1499
3.1509156227111816,30,1549
2.83652925491333,31,1599
2.6881754398345947,32,1649
2.807206392288208,33,1699
2.5723464488983154,34,1749
2.6681864261627197,35,1799
2.7239675521850586,36,1849
2.5779123306274414,37,1899
2.515653371810913,38,1949
2.745894193649292,39,1999
2.495800256729126,40,2049
2.6727285385131836,41,2099
2.6207997798919678,42,2149
2.4270260334014893,43,2199
2.6055679321289062,44,2249
2.950937509536743,45,2299
2.748549222946167,46,2349
2.5711565017700195,47,2399
2.4976909160614014,48,2449
2.6239163875579834,49,2499
