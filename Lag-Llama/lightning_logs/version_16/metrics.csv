train_loss,epoch,step
9.922968864440918,0,49
8.910719871520996,1,99
8.693260192871094,2,149
8.582993507385254,3,199
8.488932609558105,4,249
8.32445240020752,5,299
8.23998737335205,6,349
8.565443992614746,7,399
8.025327682495117,8,449
7.958712577819824,9,499
7.772578239440918,10,549
7.681272983551025,11,599
7.759366512298584,12,649
7.641992568969727,13,699
7.5299601554870605,14,749
7.435812950134277,15,799
7.3995442390441895,16,849
7.370627403259277,17,899
7.365108013153076,18,949
7.362773418426514,19,999
7.310311794281006,20,1049
7.203076362609863,21,1099
7.136012077331543,22,1149
7.405686855316162,23,1199
7.314099311828613,24,1249
7.001239776611328,25,1299
7.006061553955078,26,1349
6.9834394454956055,27,1399
7.020977973937988,28,1449
6.874722957611084,29,1499
6.880924224853516,30,1549
6.9741129875183105,31,1599
7.218839168548584,32,1649
6.999013900756836,33,1699
6.867710590362549,34,1749
6.939423084259033,35,1799
6.710233211517334,36,1849
6.748943328857422,37,1899
6.7425432205200195,38,1949
6.666142463684082,39,1999
6.750406265258789,40,2049
6.623928070068359,41,2099
6.56089973449707,42,2149
6.996659755706787,43,2199
6.5931878089904785,44,2249
6.523832321166992,45,2299
6.5692458152771,46,2349
6.71474552154541,47,2399
6.537591934204102,48,2449
6.443209171295166,49,2499
