{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Description\n",
    "\n",
    "\n",
    "The code below is a simple example of forecasting using the **Time-Moe** model. Time-Moe is an advanced forecasting model that can handle time series data, taking into account the variability and complexity of the data over time. This example demonstrates the application of the model to predict future values based on historical data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda3/envs/rapids-24.06/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "import numpy as np\n",
    "\n",
    "context_length = 12\n",
    "seqs = torch.randn(1, context_length)  # tensor shape is [batch_size, context_length]\n",
    "\n",
    "# print(seqs)\n",
    "array = np.array([[0.6043895],\n",
    "                  [0.6255155],\n",
    "                  [0.6164969],\n",
    "                  [0.66817744],\n",
    "                  [0.55820169],\n",
    "                  [0.93960934],\n",
    "                  [0.63104171],\n",
    "                  [0.53867273],\n",
    "                  [0.59735362],\n",
    "                  [0.48445419],\n",
    "                  [0.45488705],\n",
    "                  [0.37924489],\n",
    "                  [0.5468614],\n",
    "                  [0.25627887]])\n",
    "\n",
    "tensor = torch.tensor(array, dtype=torch.float32)\n",
    "\n",
    "tensor = tensor.squeeze(-1).unsqueeze(0)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    'Maple728/TimeMoE-50M',\n",
    "    device_map=\"cpu\",  # use \"cpu\" for CPU inference, and \"cuda\" for GPU inference.\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "# forecast\n",
    "prediction_length = 12\n",
    "output = model.generate(tensor, max_new_tokens=prediction_length)  # shape is [batch_size, 12 + 6]\n",
    "normed_predictions = output[:, -prediction_length:]  # shape is [batch_size, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2842, 0.2792, 0.2963, 0.2776, 0.2778, 0.2660, 0.2847, 0.2845, 0.2842,\n",
       "         0.2872, 0.3008, 0.3278]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normed_predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-24.06",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
